{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d34fc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable autoreload for hot reloading modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60b4da6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/checkpoint/avseal/tuantran/env_srcs/editguard/editguard/code',\n",
       " '/checkpoint/avseal/tuantran/envs/editguard/lib/python310.zip',\n",
       " '/checkpoint/avseal/tuantran/envs/editguard/lib/python3.10',\n",
       " '/checkpoint/avseal/tuantran/envs/editguard/lib/python3.10/lib-dynload',\n",
       " '',\n",
       " '/checkpoint/avseal/tuantran/envs/editguard/lib/python3.10/site-packages']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# Some how videoseal is added to sys.path at index 0, which causes conflicts\n",
    "# Remove it to avoid import issues\n",
    "if \"videoseal\" in sys.path[0]:\n",
    "    del sys.path[0]\n",
    "\n",
    "\n",
    "sys.path.insert(0, \"/checkpoint/avseal/tuantran/env_srcs/editguard/editguard/code\")  \n",
    "\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30b2219",
   "metadata": {},
   "source": [
    "## Loading eager mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bf22ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export CUDA_VISIBLE_DEVICES=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/checkpoint/avseal/tuantran/envs/editguard/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEAttention\n",
      "SEAttention\n",
      "SEAttention\n",
      "SEAttention\n",
      "SEAttention\n",
      "SEAttention\n",
      "SEAttention\n",
      "SEAttention\n",
      "SEAttention\n",
      "SEAttention\n",
      "SEAttention\n",
      "SEAttention\n",
      "SEAttention\n",
      "SEAttention\n",
      "SEAttention\n",
      "SEAttention\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...:   0%|                                                                                                                                                                                                                                     | 0/5 [00:00<?, ?it/s]An error occurred while trying to fetch /checkpoint/avseal/cache/huggingface/hub/models--philschmid--stable-diffusion-2-inpainting-endpoint/snapshots/13a0c9d3340289950648a93a0432f2db27531b99/vae: Error no file named diffusion_pytorch_model.safetensors found in directory /checkpoint/avseal/cache/huggingface/hub/models--philschmid--stable-diffusion-2-inpainting-endpoint/snapshots/13a0c9d3340289950648a93a0432f2db27531b99/vae.\n",
      "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
      "Loading pipeline components...:  60%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                        | 3/5 [00:00<00:00,  5.15it/s]An error occurred while trying to fetch /checkpoint/avseal/cache/huggingface/hub/models--philschmid--stable-diffusion-2-inpainting-endpoint/snapshots/13a0c9d3340289950648a93a0432f2db27531b99/unet: Error no file named diffusion_pytorch_model.safetensors found in directory /checkpoint/avseal/cache/huggingface/hub/models--philschmid--stable-diffusion-2-inpainting-endpoint/snapshots/13a0c9d3340289950648a93a0432f2db27531b99/unet.\n",
      "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
      "Loading pipeline components...:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                            | 4/5 [00:01<00:00,  2.06it/s]`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading pipeline components...: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:02<00:00,  1.76it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "import models.networks as networks\n",
    "from data.test_dataset_td import imageTestDataset as D\n",
    "import options.options as option\n",
    "from models import create_model\n",
    "\n",
    "device = \"cuda\"\n",
    "opt = option.parse(\"/checkpoint/avseal/tuantran/env_srcs/editguard/editguard/code/options/test_editguard.yml\", is_train=False)\n",
    "opt = option.dict_to_nonedict(opt)\n",
    "\n",
    "opt['datasets']['TD']['data_path'] = 'dataset/valAGE-Set'\n",
    "opt['datasets']['TD']['txt_path'] = 'dataset/sep_testlist.txt'\n",
    "\n",
    "# Load datasetb\n",
    "dataset = D(opt['datasets']['TD'])\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False, num_workers=1, pin_memory=True)\n",
    "\n",
    "model = create_model(opt)\n",
    "model.load_test(\"/checkpoint/avseal/tuantran/omnisealbench/checkpoints/editguard/clean.pth\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "674dc1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:05<00:00,  9.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "from utils import util\n",
    "\n",
    "for image_id, val_data in enumerate(dataloader):\n",
    "    model.feed_data(val_data)\n",
    "    print(image_id)\n",
    "    model.test(image_id, masksrc=\"dataset/valAGE-Set-Mask/\")\n",
    "    \n",
    "    visuals = model.get_current_visuals()\n",
    "    \n",
    "    t_step = visuals['SR'].shape[0]\n",
    "    n = len(visuals['SR_h'])\n",
    "\n",
    "    a = visuals['recmessage'][0]\n",
    "    b = visuals['message'][0]\n",
    "\n",
    "    bitrecord = util.decoded_message_error_rate_batch(a, b)\n",
    "    print(bitrecord)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b51f1a",
   "metadata": {},
   "source": [
    "## Loading jit mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ce55f18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 3, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "for image_id, val_data in enumerate(dataloader):\n",
    "    print(val_data[\"GT\"].shape)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6210d78a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 'DWT and IWT are not consistent')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.modules.common import DWT,IWT\n",
    "\n",
    "dwt = DWT()\n",
    "iwt = IWT()\n",
    "\n",
    "val_data_1 = dwt(val_data[\"GT\"].squeeze(0))\n",
    "val_data_2 = iwt(val_data_1)\n",
    "\n",
    "torch.testing.assert_close(val_data[\"GT\"].squeeze(0).cpu(), val_data_2.cpu()), \"DWT and IWT are not consistent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d57a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 3, 512, 512])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript, serialized code (most recent call last):\n  File \"code/__torch__/models/bitnetwork/Encoder_U.py\", line 34, in forward\n    _0 = __torch__.torch.nn.functional.___torch_mangle_145.interpolate\n    conv1 = self.conv1\n    d0 = (conv1).forward(x, )\n          ~~~~~~~~~~~~~~ <--- HERE\n    down1 = self.down1\n    d1 = (down1).forward(d0, )\n  File \"code/__torch__/models/bitnetwork/ConvBlock.py\", line 10, in forward\n    x: Tensor) -> Tensor:\n    layers = self.layers\n    return (layers).forward(x, )\n            ~~~~~~~~~~~~~~~ <--- HERE\nclass ConvINRelu(Module):\n  __parameters__ = []\n  File \"code/__torch__/torch/nn/modules/container/___torch_mangle_3.py\", line 12, in forward\n    _0 = getattr(self, \"0\")\n    _1 = getattr(self, \"1\")\n    input0 = (_0).forward(input, )\n              ~~~~~~~~~~~ <--- HERE\n    return (_1).forward(input0, )\n  def __len__(self: __torch__.torch.nn.modules.container.___torch_mangle_3.Sequential) -> int:\n  File \"code/__torch__/models/bitnetwork/ConvBlock.py\", line 20, in forward\n    x: Tensor) -> Tensor:\n    layers = self.layers\n    return (layers).forward(x, )\n            ~~~~~~~~~~~~~~~ <--- HERE\n  File \"code/__torch__/torch/nn/modules/container.py\", line 14, in forward\n    _1 = getattr(self, \"1\")\n    _2 = getattr(self, \"2\")\n    input0 = (_0).forward(input, )\n              ~~~~~~~~~~~ <--- HERE\n    input1 = (_1).forward(input0, )\n    return (_2).forward(input1, )\n  File \"code/__torch__/torch/nn/modules/conv.py\", line 23, in forward\n    weight = self.weight\n    bias = self.bias\n    _0 = (self)._conv_forward(input, weight, bias, )\n          ~~~~~~~~~~~~~~~~~~~ <--- HERE\n    return _0\n  def _conv_forward(self: __torch__.torch.nn.modules.conv.Conv2d,\n  File \"code/__torch__/torch/nn/modules/conv.py\", line 29, in _conv_forward\n    weight: Tensor,\n    bias: Optional[Tensor]) -> Tensor:\n    _1 = torch.conv2d(input, weight, bias, [1, 1], [1, 1], [1, 1])\n         ~~~~~~~~~~~~ <--- HERE\n    return _1\n\nTraceback of TorchScript, original code (most recent call last):\n  File \"/checkpoint/avseal/tuantran/env_srcs/editguard/editguard/code/models/bitnetwork/Encoder_U.py\", line 46, in forward\n    def forward(self, x, watermark):\n        d0 = self.conv1(x)\n             ~~~~~~~~~~ <--- HERE\n        d1 = self.down1(d0)\n        d2 = self.down2(d1)\n  File \"/checkpoint/avseal/tuantran/env_srcs/editguard/editguard/code/models/bitnetwork/ConvBlock.py\", line 38, in forward\n\tdef forward(self, x):\n\t\treturn self.layers(x)\n         ~~~~~~~~~~~ <--- HERE\n  File \"/checkpoint/avseal/tuantran/envs/editguard/lib/python3.10/site-packages/torch/nn/modules/container.py\", line 250, in forward\n        \"\"\"\n        for module in self:\n            input = module(input)\n                    ~~~~~~ <--- HERE\n        return input\n  File \"/checkpoint/avseal/tuantran/env_srcs/editguard/editguard/code/models/bitnetwork/ConvBlock.py\", line 19, in forward\n\tdef forward(self, x):\n\t\treturn self.layers(x)\n         ~~~~~~~~~~~ <--- HERE\n  File \"/checkpoint/avseal/tuantran/envs/editguard/lib/python3.10/site-packages/torch/nn/modules/container.py\", line 250, in forward\n        \"\"\"\n        for module in self:\n            input = module(input)\n                    ~~~~~~ <--- HERE\n        return input\n  File \"/checkpoint/avseal/tuantran/envs/editguard/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 548, in forward\n    def forward(self, input: Tensor) -> Tensor:\n        return self._conv_forward(input, self.weight, self.bias)\n               ~~~~~~~~~~~~~~~~~~ <--- HERE\n  File \"/checkpoint/avseal/tuantran/envs/editguard/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 543, in _conv_forward\n                self.groups,\n            )\n        return F.conv2d(\n               ~~~~~~~~ <--- HERE\n            input, weight, bias, self.stride, self.padding, self.dilation, self.groups\n        )\nRuntimeError: Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [1, 1, 3, 512, 512]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m host \u001b[38;5;241m=\u001b[39m real_H[:,center:center \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(host\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 37\u001b[0m output_y, _ \u001b[38;5;241m=\u001b[39m \u001b[43mbitencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m output_y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mclamp(output_y, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     39\u001b[0m output_y \u001b[38;5;241m=\u001b[39m (output_y \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m255.\u001b[39m)\u001b[38;5;241m.\u001b[39mround() \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.\u001b[39m\n",
      "File \u001b[0;32m/checkpoint/avseal/tuantran/envs/editguard/lib/python3.10/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/checkpoint/avseal/tuantran/envs/editguard/lib/python3.10/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript, serialized code (most recent call last):\n  File \"code/__torch__/models/bitnetwork/Encoder_U.py\", line 34, in forward\n    _0 = __torch__.torch.nn.functional.___torch_mangle_145.interpolate\n    conv1 = self.conv1\n    d0 = (conv1).forward(x, )\n          ~~~~~~~~~~~~~~ <--- HERE\n    down1 = self.down1\n    d1 = (down1).forward(d0, )\n  File \"code/__torch__/models/bitnetwork/ConvBlock.py\", line 10, in forward\n    x: Tensor) -> Tensor:\n    layers = self.layers\n    return (layers).forward(x, )\n            ~~~~~~~~~~~~~~~ <--- HERE\nclass ConvINRelu(Module):\n  __parameters__ = []\n  File \"code/__torch__/torch/nn/modules/container/___torch_mangle_3.py\", line 12, in forward\n    _0 = getattr(self, \"0\")\n    _1 = getattr(self, \"1\")\n    input0 = (_0).forward(input, )\n              ~~~~~~~~~~~ <--- HERE\n    return (_1).forward(input0, )\n  def __len__(self: __torch__.torch.nn.modules.container.___torch_mangle_3.Sequential) -> int:\n  File \"code/__torch__/models/bitnetwork/ConvBlock.py\", line 20, in forward\n    x: Tensor) -> Tensor:\n    layers = self.layers\n    return (layers).forward(x, )\n            ~~~~~~~~~~~~~~~ <--- HERE\n  File \"code/__torch__/torch/nn/modules/container.py\", line 14, in forward\n    _1 = getattr(self, \"1\")\n    _2 = getattr(self, \"2\")\n    input0 = (_0).forward(input, )\n              ~~~~~~~~~~~ <--- HERE\n    input1 = (_1).forward(input0, )\n    return (_2).forward(input1, )\n  File \"code/__torch__/torch/nn/modules/conv.py\", line 23, in forward\n    weight = self.weight\n    bias = self.bias\n    _0 = (self)._conv_forward(input, weight, bias, )\n          ~~~~~~~~~~~~~~~~~~~ <--- HERE\n    return _0\n  def _conv_forward(self: __torch__.torch.nn.modules.conv.Conv2d,\n  File \"code/__torch__/torch/nn/modules/conv.py\", line 29, in _conv_forward\n    weight: Tensor,\n    bias: Optional[Tensor]) -> Tensor:\n    _1 = torch.conv2d(input, weight, bias, [1, 1], [1, 1], [1, 1])\n         ~~~~~~~~~~~~ <--- HERE\n    return _1\n\nTraceback of TorchScript, original code (most recent call last):\n  File \"/checkpoint/avseal/tuantran/env_srcs/editguard/editguard/code/models/bitnetwork/Encoder_U.py\", line 46, in forward\n    def forward(self, x, watermark):\n        d0 = self.conv1(x)\n             ~~~~~~~~~~ <--- HERE\n        d1 = self.down1(d0)\n        d2 = self.down2(d1)\n  File \"/checkpoint/avseal/tuantran/env_srcs/editguard/editguard/code/models/bitnetwork/ConvBlock.py\", line 38, in forward\n\tdef forward(self, x):\n\t\treturn self.layers(x)\n         ~~~~~~~~~~~ <--- HERE\n  File \"/checkpoint/avseal/tuantran/envs/editguard/lib/python3.10/site-packages/torch/nn/modules/container.py\", line 250, in forward\n        \"\"\"\n        for module in self:\n            input = module(input)\n                    ~~~~~~ <--- HERE\n        return input\n  File \"/checkpoint/avseal/tuantran/env_srcs/editguard/editguard/code/models/bitnetwork/ConvBlock.py\", line 19, in forward\n\tdef forward(self, x):\n\t\treturn self.layers(x)\n         ~~~~~~~~~~~ <--- HERE\n  File \"/checkpoint/avseal/tuantran/envs/editguard/lib/python3.10/site-packages/torch/nn/modules/container.py\", line 250, in forward\n        \"\"\"\n        for module in self:\n            input = module(input)\n                    ~~~~~~ <--- HERE\n        return input\n  File \"/checkpoint/avseal/tuantran/envs/editguard/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 548, in forward\n    def forward(self, input: Tensor) -> Tensor:\n        return self._conv_forward(input, self.weight, self.bias)\n               ~~~~~~~~~~~~~~~~~~ <--- HERE\n  File \"/checkpoint/avseal/tuantran/envs/editguard/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 543, in _conv_forward\n                self.groups,\n            )\n        return F.conv2d(\n               ~~~~~~~~ <--- HERE\n            input, weight, bias, self.stride, self.padding, self.dilation, self.groups\n        )\nRuntimeError: Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [1, 1, 3, 512, 512]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from utils import util\n",
    "\n",
    "bitencoder = torch.jit.load(\"/checkpoint/avseal/models/baselines-watermarking/editguard_encoder.pt\")\n",
    "bitencoder = bitencoder.eval().to(device)\n",
    "\n",
    "bitdecoder = torch.jit.load(\"/checkpoint/avseal/models/baselines-watermarking/editguard_decoder.pt\")\n",
    "bitdecoder = bitdecoder.eval().to(device)\n",
    "\n",
    "def dwt_init(x):\n",
    "\n",
    "    x01 = x[:, :, 0::2, :] / 2\n",
    "    x02 = x[:, :, 1::2, :] / 2\n",
    "    x1 = x01[:, :, :, 0::2]\n",
    "    x2 = x02[:, :, :, 0::2]\n",
    "    x3 = x01[:, :, :, 1::2]\n",
    "    x4 = x02[:, :, :, 1::2]\n",
    "    x_LL = x1 + x2 + x3 + x4\n",
    "    x_HL = -x1 - x2 + x3 + x4\n",
    "    x_LH = -x1 + x2 - x3 + x4\n",
    "    x_HH = x1 - x2 - x3 + x4\n",
    "\n",
    "    return torch.cat((x_LL, x_HL, x_LH, x_HH), 1)\n",
    "\n",
    "bsz = 1\n",
    "messagenp = np.random.choice([-0.5, 0.5], (bsz, 64))\n",
    "msg = torch.Tensor(messagenp).to(device)\n",
    "\n",
    "for image_id, val_data in enumerate(dataloader):\n",
    "    \n",
    "    real_H = val_data[\"GT\"].to(device)\n",
    "    b, t, c, h, w = real_H.shape\n",
    "    center = t // 2\n",
    "\n",
    "    host = real_H[:,center:center + 1].squeeze(0)\n",
    "    print(host.shape)\n",
    "    output_y, _ = bitencoder(host, msg)\n",
    "    output_y = torch.clamp(output_y, 0, 1)\n",
    "    output_y = (output_y * 255.).round() / 255.\n",
    "    \n",
    "    rec_msg = bitdecoder(output_y)\n",
    "    msg = torch.clamp(msg, -0.5, 0.5)\n",
    "    rec_msg = torch.clamp(rec_msg, -0.5, 0.5)\n",
    "    \n",
    "    bitrecord = util.decoded_message_error_rate_batch(msg, rec_msg)\n",
    "    print(bitrecord)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf9fc913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.netG.module.bitencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14ac1da",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Model_VSN' object has no attribute 'bitdecoder'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m bitdecoder \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbitdecoder\u001b[49m\n\u001b[1;32m      2\u001b[0m jit_decoder \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mscript(bitdecoder)  \u001b[38;5;66;03m# example_inputs=(torch.randn(1\u001b[39;00m\n\u001b[1;32m      4\u001b[0m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39msave(jit_decoder, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/checkpoint/avseal/models/baselines-watermarking/editguard_encoder.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Model_VSN' object has no attribute 'bitdecoder'"
     ]
    }
   ],
   "source": [
    "bitdecoder = model.netG.bitencoder\n",
    "jit_decoder = torch.jit.script(bitdecoder)  # example_inputs=(torch.randn(1\n",
    "\n",
    "torch.jit.save(jit_decoder, \"/checkpoint/avseal/models/baselines-watermarking/editguard_encoder.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
